# -*- coding: utf-8 -*-
"""Customer segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MQiJwRyUwLDnWsD1rXmc1PHdZOOEqH-k

# Part 1: Data preprocessing

dataset link: https://www.kaggle.com/arjunbhasin2013/ccdata?select=CC+GENERAL.csv

## Importing the libraries and the dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/CC GENERAL.csv')

dataset.head()

"""## Data exploration"""

dataset.shape

dataset.columns

dataset.info()

# categorical columns
dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

# numerical columns
dataset.select_dtypes(include=['int64','float64']).columns

len(dataset.select_dtypes(include=['int64','float64']).columns)

# statistical summary
dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

dataset.columns[dataset.isnull().any()]

len(dataset.columns[dataset.isnull().any()])

dataset['CREDIT_LIMIT'] = dataset['CREDIT_LIMIT'].fillna(dataset['CREDIT_LIMIT'].mean())
dataset['MINIMUM_PAYMENTS'] = dataset['MINIMUM_PAYMENTS'].fillna(dataset['MINIMUM_PAYMENTS'].mean())

len(dataset.columns[dataset.isnull().any()])

"""## Encoding categorical data"""

# categorical columns
dataset.select_dtypes(include='object').columns

dataset.head()

dataset = dataset.drop(columns='CUST_ID')

dataset.head()

# categorical columns
dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

"""## Correlation matrix"""

corr = dataset.corr()

# heatmap
plt.figure(figsize=(16,9))
ax = sns.heatmap(corr, annot=True, cmap='coolwarm')

"""## Splitting the dataset"""

# only independent variables not target variable

"""## Feature scaling"""

df = dataset

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
dataset = sc.fit_transform(dataset)

dataset

"""# Part 2: Elbow method (finding the optimal number of clusters)"""

from sklearn.cluster import KMeans

wcss = []
for i in range(1, 20):
  kmeans = KMeans(n_clusters=i, init='k-means++')
  kmeans.fit(dataset)
  wcss.append(kmeans.inertia_)
plt.plot(range(1, 20), wcss, 'bx-')
plt.title('The Elbo method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""# Part 3: Building the model"""

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=8, init='k-means++', random_state=0)

# dependent variable
y_kmeans = kmeans.fit_predict(dataset)

y_kmeans

"""# Part 4: Getting the output"""

y_kmeans.shape

y_kmeans =  y_kmeans.reshape(len(y_kmeans), 1)

y_kmeans.shape

b = np.concatenate((y_kmeans, df), axis=1)

df.columns

df_final = pd.DataFrame(data=b, columns=['Cluster_Number','BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES', 'ONEOFF_PURCHASES',
       'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'PURCHASES_FREQUENCY',
       'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY',
       'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX',
       'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT',
       'TENURE'])

df_final.head()

df_final.to_csv('Segmented_customers')